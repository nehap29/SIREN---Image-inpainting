{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Resize, Compose, ToTensor, Normalize\n",
    "import numpy as np\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage\n",
    "from cv2 import imread\n",
    "import time\n",
    "\n",
    "def get_mgrid(sidelen, dim=2):\n",
    "    '''Generates a flattened grid of (x,y,...) coordinates in a range of -1 to 1.\n",
    "    sidelen: int\n",
    "    dim: int'''\n",
    "    tensors = tuple(dim * [torch.linspace(-1, 1, steps=sidelen)])\n",
    "    mgrid = torch.stack(torch.meshgrid(*tensors), dim=-1)\n",
    "    mgrid = mgrid.reshape(-1, dim)\n",
    "    return mgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SineLayer(nn.Module):\n",
    "    # See paper sec. 3.2, final paragraph, and supplement Sec. 1.5 for discussion of omega_0.\n",
    "    \n",
    "    # If is_first=True, omega_0 is a frequency factor which simply multiplies the activations before the \n",
    "    # nonlinearity. Different signals may require different omega_0 in the first layer - this is a \n",
    "    # hyperparameter.\n",
    "    \n",
    "    # If is_first=False, then the weights will be divided by omega_0 so as to keep the magnitude of \n",
    "    # activations constant, but boost gradients to the weight matrix (see supplement Sec. 1.5)\n",
    "    \n",
    "    def __init__(self, in_features, out_features, bias=True,\n",
    "                 is_first=False, omega_0=30):\n",
    "        super().__init__()\n",
    "        self.omega_0 = omega_0\n",
    "        self.is_first = is_first\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            if self.is_first:\n",
    "                self.linear.weight.uniform_(-1 / self.in_features, \n",
    "                                             1 / self.in_features)      \n",
    "            else:\n",
    "                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0, \n",
    "                                             np.sqrt(6 / self.in_features) / self.omega_0)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return torch.sin(self.omega_0 * self.linear(input))\n",
    "    \n",
    "    def forward_with_intermediate(self, input): \n",
    "        # For visualization of activation distributions\n",
    "        intermediate = self.omega_0 * self.linear(input)\n",
    "        return torch.sin(intermediate), intermediate\n",
    "    \n",
    "    \n",
    "class Siren(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, hidden_layers, out_features, outermost_linear=False, \n",
    "                 first_omega_0=30, hidden_omega_0=30.):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = []\n",
    "        self.net.append(SineLayer(in_features, hidden_features, \n",
    "                                  is_first=True, omega_0=first_omega_0))\n",
    "\n",
    "        for i in range(hidden_layers):\n",
    "            self.net.append(SineLayer(hidden_features, hidden_features, \n",
    "                                      is_first=False, omega_0=hidden_omega_0))\n",
    "\n",
    "        if outermost_linear:\n",
    "            final_linear = nn.Linear(hidden_features, out_features)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                final_linear.weight.uniform_(-np.sqrt(6 / hidden_features) / hidden_omega_0, \n",
    "                                              np.sqrt(6 / hidden_features) / hidden_omega_0)\n",
    "                \n",
    "            self.net.append(final_linear)\n",
    "        else:\n",
    "            self.net.append(SineLayer(hidden_features, out_features, \n",
    "                                      is_first=False, omega_0=hidden_omega_0))\n",
    "        \n",
    "        self.net = nn.Sequential(*self.net)\n",
    "    \n",
    "    def forward(self, coords):\n",
    "        coords = coords.clone().detach().requires_grad_(True) # allows to take derivative w.r.t. input\n",
    "        output = self.net(coords)\n",
    "        return output, coords        \n",
    "\n",
    "    def forward_with_activations(self, coords, retain_grad=False):\n",
    "        '''Returns not only model output, but also intermediate activations.\n",
    "        Only used for visualizing activations later!'''\n",
    "        activations = OrderedDict()\n",
    "\n",
    "        activation_count = 0\n",
    "        x = coords.clone().detach().requires_grad_(True)\n",
    "        activations['input'] = x\n",
    "        for i, layer in enumerate(self.net):\n",
    "            if isinstance(layer, SineLayer):\n",
    "                x, intermed = layer.forward_with_intermediate(x)\n",
    "                \n",
    "                if retain_grad:\n",
    "                    x.retain_grad()\n",
    "                    intermed.retain_grad()\n",
    "                    \n",
    "                activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = intermed\n",
    "                activation_count += 1\n",
    "            else: \n",
    "                x = layer(x)\n",
    "                \n",
    "                if retain_grad:\n",
    "                    x.retain_grad()\n",
    "                    \n",
    "            activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = x\n",
    "            activation_count += 1\n",
    "\n",
    "        return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace(y, x):\n",
    "    grad = gradient(y, x)\n",
    "    return divergence(grad, x)\n",
    "\n",
    "\n",
    "def divergence(y, x):\n",
    "    div = 0.\n",
    "    for i in range(y.shape[-1]):\n",
    "        div += torch.autograd.grad(y[..., i], x, torch.ones_like(y[..., i]), create_graph=True)[0][..., i:i+1]\n",
    "    return div\n",
    "\n",
    "\n",
    "def gradient(y, x, grad_outputs=None):\n",
    "    if grad_outputs is None:\n",
    "        grad_outputs = torch.ones_like(y)\n",
    "    grad = torch.autograd.grad(y, [x], grad_outputs=grad_outputs, create_graph=True)[0]\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cameraman_tensor(sidelength):\n",
    "    img = Image.fromarray(skimage.data.camera())        \n",
    "    transform = Compose([\n",
    "        Resize(sidelength),\n",
    "        ToTensor(),\n",
    "        Normalize(torch.Tensor([0.5]), torch.Tensor([0.5]))\n",
    "    ])\n",
    "    img = transform(img)\n",
    "    return img\n",
    "\n",
    "def get_brick_tensor(sidelength):\n",
    "    img = Image.fromarray(skimage.data.brick())        \n",
    "    transform = Compose([\n",
    "        Resize(sidelength),\n",
    "        ToTensor(),\n",
    "        Normalize(torch.Tensor([0.5]), torch.Tensor([0.5]))\n",
    "    ])\n",
    "    img = transform(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompositeGradients(Dataset):\n",
    "    def __init__(self, img_filepath1, img_filepath2,\n",
    "                 sidelength=None,\n",
    "                 is_color=False):\n",
    "        super().__init__()\n",
    "\n",
    "        #if isinstance(sidelength, int):\n",
    "          #  sidelength = (sidelength, sidelength)\n",
    "\n",
    "        self.is_color = is_color\n",
    "        if (self.is_color):\n",
    "            self.channels = 3\n",
    "        else:\n",
    "            self.channels = 1\n",
    "\n",
    "        self.img1 = Image.open(img_filepath1)\n",
    "        self.img2 = Image.open(img_filepath2)\n",
    "\n",
    "        if not self.is_color:\n",
    "            self.img1 = self.img1.convert(\"L\")\n",
    "            self.img2 = self.img2.convert(\"L\")\n",
    "        else:\n",
    "            self.img1 = self.img1.convert(\"RGB\")\n",
    "            self.img2 = self.img2.convert(\"RGB\")\n",
    "\n",
    "        self.transform = Compose([\n",
    "            ToTensor(),\n",
    "            Normalize(torch.Tensor([0.5]), torch.Tensor([0.5]))\n",
    "        ])\n",
    "\n",
    "        print(sidelength)\n",
    "        self.mgrid = get_mgrid(int(sidelength))\n",
    "\n",
    "        self.img1 = self.transform(self.img1)\n",
    "        self.img2 = self.transform(self.img2)\n",
    "\n",
    "        paddedImg = .85 * torch.ones_like(self.img1)\n",
    "        print(self.img1.numpy().shape)\n",
    "        print(self.img2.numpy().shape)\n",
    "        paddedImg[:, self.img1.shape[1] - self.img2.shape[1]:self.img1.shape[1], :] = self.img2\n",
    "        self.img2 = paddedImg\n",
    "\n",
    "        self.grads1 = self.compute_gradients(self.img1)\n",
    "        self.grads2 = self.compute_gradients(self.img2)\n",
    "\n",
    "        self.comp_grads = (.5 * self.grads1 + .5 * self.grads2)\n",
    "\n",
    "        self.img1 = self.img1.permute(1, 2, 0).view(-1, self.channels)\n",
    "        self.img2 = self.img2.permute(1, 2, 0).view(-1, self.channels)\n",
    "\n",
    "    def compute_gradients(self, img):\n",
    "        if not self.is_color:\n",
    "            gradx = scipy.ndimage.sobel(img.numpy(), axis=1).squeeze(0)[..., None]\n",
    "            grady = scipy.ndimage.sobel(img.numpy(), axis=2).squeeze(0)[..., None]\n",
    "        else:\n",
    "            gradx = np.moveaxis(scipy.ndimage.sobel(img.numpy(), axis=1), 0, -1)\n",
    "            grady = np.moveaxis(scipy.ndimage.sobel(img.numpy(), axis=2), 0, -1)\n",
    "\n",
    "        grads = torch.cat((torch.from_numpy(gradx).reshape(-1, self.channels),\n",
    "                           torch.from_numpy(grady).reshape(-1, self.channels)),\n",
    "                          dim=-1)\n",
    "        return grads\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        in_dict = {'idx': idx, 'pixels': self.mgrid}\n",
    "        gt_dict = {'img1': self.img1,\n",
    "                   'img2': self.img2,\n",
    "                   'grads1': self.grads1,\n",
    "                   'grads2': self.grads2,\n",
    "                   'grads': self.comp_grads}\n",
    "\n",
    "        return in_dict['pixels'], gt_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFitting(Dataset):\n",
    "    def __init__(self, sidelength):\n",
    "        super().__init__()\n",
    "        img = get_cameraman_tensor(sidelength)\n",
    "        self.pixels = img.permute(1, 2, 0).view(-1, 1)\n",
    "        self.coords = get_mgrid(sidelength, 2)\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "    def __getitem__(self, idx):    \n",
    "        if idx > 0: raise IndexError\n",
    "            \n",
    "        return self.coords, self.pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoissonEqn(Dataset):\n",
    "    def __init__(self, sidelength):\n",
    "        super().__init__()\n",
    "        man = get_cameraman_tensor(sidelength)\n",
    "        brick = get_brick_tensor(sidelength)\n",
    "        \n",
    "        img = man / 2 + brick / 2\n",
    "        \n",
    "        # Compute gradient and laplacian       \n",
    "        grads_x_man = scipy.ndimage.sobel(man.numpy(), axis=1).squeeze(0)[..., None]\n",
    "        grads_y_man = scipy.ndimage.sobel(man.numpy(), axis=2).squeeze(0)[..., None]\n",
    "        grads_x_man, grads_y_man = torch.from_numpy(grads_x_man), torch.from_numpy(grads_y_man)\n",
    "        \n",
    "        grads_x_brick = scipy.ndimage.sobel(brick.numpy(), axis=1).squeeze(0)[..., None]\n",
    "        grads_y_brick = scipy.ndimage.sobel(brick.numpy(), axis=2).squeeze(0)[..., None]\n",
    "        grads_x_brick, grads_y_brick = torch.from_numpy(grads_x_brick), torch.from_numpy(grads_y_brick)\n",
    "        \n",
    "        grads_x = scipy.ndimage.sobel(img.numpy(), axis=1).squeeze(0)[..., None]\n",
    "        grads_y = scipy.ndimage.sobel(img.numpy(), axis=2).squeeze(0)[..., None]\n",
    "        grads_x, grads_y = torch.from_numpy(grads_x), torch.from_numpy(grads_y)\n",
    "                \n",
    "        self.grads = torch.stack((grads_x, grads_y), dim=-1).view(-1, 2)\n",
    "        self.laplace = scipy.ndimage.laplace(img.numpy()).squeeze(0)[..., None]\n",
    "        self.laplace = torch.from_numpy(self.laplace)\n",
    "        \n",
    "        self.pixels = img.permute(1, 2, 0).view(-1, 1)\n",
    "        self.coords = get_mgrid(sidelength, 2)\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.coords, {'pixels':self.pixels, 'grads':self.grads, 'laplace':self.laplace}\n",
    "    \n",
    "class PoissonCustomEqn(Dataset):\n",
    "    def __init__(self, sidelength, path_1, path_2):\n",
    "        super().__init__()\n",
    "        img_1 = get_img_tensor(path_1,sidelength)\n",
    "        img_2 = get_img_tensor(path_2,int(sidelength/2))\n",
    "        print(img_1.numpy().shape)\n",
    "        print(img_2.numpy().shape)\n",
    "        img = img_1 / 2 + img_2 / 2\n",
    "        \n",
    "        # Compute gradient and laplacian\n",
    "        grads_x = scipy.ndimage.sobel(img.numpy(), axis=1).squeeze(0)[..., None]\n",
    "        grads_y = scipy.ndimage.sobel(img.numpy(), axis=2).squeeze(0)[..., None]\n",
    "        grads_x, grads_y = torch.from_numpy(grads_x), torch.from_numpy(grads_y)\n",
    "                \n",
    "        self.grads = torch.stack((grads_x, grads_y), dim=-1).view(-1, 2)\n",
    "        self.laplace = scipy.ndimage.laplace(img_1.numpy()).squeeze(0)[..., None]\n",
    "        self.laplace = torch.from_numpy(self.laplace)\n",
    "        \n",
    "        self.pixels = img.permute(1, 2, 0).view(-1, 1)\n",
    "        self.coords = get_mgrid(sidelength, 2)\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.coords, {'pixels':self.pixels, 'grads':self.grads, 'laplace':self.laplace}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "(1, 1804, 1200)\n",
      "(1, 925, 1200)\n"
     ]
    }
   ],
   "source": [
    "cameraman_poisson = CompositeGradients('room.jpg','sofa.jpg',is_color=False, sidelength=512)\n",
    "dataloader = DataLoader(cameraman_poisson, batch_size=1, pin_memory=True, num_workers=0)\n",
    "\n",
    "poisson_siren = Siren(in_features=2, out_features=1, hidden_features=256, \n",
    "                      hidden_layers=3, outermost_linear=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradients_mse(model_output, coords, gt_gradients):\n",
    "    # compute gradients on the model\n",
    "    gradients = gradient(model_output, coords)\n",
    "    # compare them with the ground-truth\n",
    "    gradients_loss = torch.mean((gradients - gt_gradients).pow(2).sum(-1))\n",
    "    return gradients_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (262144) must match the size of tensor b (2164800) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-abbeba2de22a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mmodel_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoisson_siren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgradients_mse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'grads'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msteps_til_summary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-42-75a4268c2e6c>\u001b[0m in \u001b[0;36mgradients_mse\u001b[1;34m(model_output, coords, gt_gradients)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# compare them with the ground-truth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mgradients_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradients\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mgt_gradients\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgradients_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (262144) must match the size of tensor b (2164800) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "total_steps = 500\n",
    "steps_til_summary = 10\n",
    "\n",
    "optim = torch.optim.Adam(lr=1e-4, params=poisson_siren.parameters())\n",
    "\n",
    "model_input, gt = next(iter(dataloader))\n",
    "gt = {key: value.cpu() for key, value in gt.items()}\n",
    "\n",
    "for step in range(total_steps):\n",
    "    start_time = time.time()\n",
    "\n",
    "    model_output, coords = poisson_siren(model_input)\n",
    "    train_loss = gradients_mse(model_output, coords, gt['grads'])\n",
    "\n",
    "    if not step % steps_til_summary:\n",
    "        print(\"Step %d, Total loss %0.6f, iteration time %0.6f\" % (step, train_loss, time.time() - start_time))\n",
    "        img_grad = gradient(model_output, coords)\n",
    "        img_laplacian = laplace(model_output, coords)\n",
    "\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "        axes[0].imshow(model_output.cpu().view(128,128).detach().numpy())\n",
    "        axes[1].imshow(img_grad.cpu().norm(dim=-1).view(128,128).detach().numpy())\n",
    "        #axes[2].imshow(img_laplacian.cpu().view(128,128).detach().numpy())\n",
    "        plt.show()\n",
    "    optim.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "img_grad = gradient(model_output, coords)\n",
    "img_laplacian = laplace(model_output, coords)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "axes[0].imshow(model_output.cpu().view(128,128).detach().numpy())\n",
    "axes[1].imshow(img_grad.cpu().norm(dim=-1).view(128,128).detach().numpy())\n",
    "axes[2].imshow(img_laplacian.cpu().view(128,128).detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
